# ğŸ§  memsearch â€” Claude Code Plugin

**Automatic persistent memory for Claude Code.** No commands to learn, no manual saving â€” just install the plugin and Claude remembers what you worked on across sessions.

```bash
# In Claude Code:
/plugin marketplace add zilliztech/memsearch
/plugin install memsearch@memsearch
```

## ğŸ’¡ Design Principles

memsearch follows two core philosophies:

**ğŸ”§ Native to Claude Code** â€” built entirely on Claude Code's own primitives: **Hooks** for lifecycle events, **CLI** for tool access, and **Agent** for autonomous decisions. No MCP servers, no sidecar services, no extra network round-trips. Everything runs locally as shell scripts and a Python CLI, keeping latency low and context window clean.

**ğŸ“ Markdown as single source of truth** â€” the same architecture that powers [OpenClaw's memory system](https://docs.openclaw.ai/concepts/memory). All knowledge lives in plain `.md` files â€” human-readable, `git`-friendly, trivially portable. The vector index (Milvus) is a **derived cache** that can be rebuilt from markdown at any time. No opaque databases, no binary blobs, no vendor lock-in.

The result: a memory system that's **simple enough to understand in 5 minutes**, yet powerful enough for production use with hybrid search (dense + BM25) and three-layer progressive disclosure.

## ğŸš€ Quick Start

### Install from Marketplace (recommended)

```bash
# 1. Install the memsearch CLI
pip install memsearch

# 2. (Optional) Initialize config
memsearch config init

# 3. In Claude Code, add the marketplace and install the plugin
/plugin marketplace add zilliztech/memsearch
/plugin install memsearch@memsearch

# 4. Have a conversation, then exit. Check your memories:
cat .memsearch/memory/$(date +%Y-%m-%d).md

# 5. Start a new session â€” Claude remembers!
```

### Development mode

For contributors or if you want to modify the plugin:

```bash
git clone https://github.com/zilliztech/memsearch.git
pip install memsearch
claude --plugin-dir ./memsearch/ccplugin
```

## âš™ï¸ How It Works

The plugin hooks into 4 Claude Code lifecycle events. A singleton `memsearch watch` process keeps the vector index in sync with markdown files in the background.

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                  ğŸ”„ memsearch plugin lifecycle                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  ğŸŸ¢ SESSION START
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SessionStart â”‚â”€â”€â”€â”€â–¶â”‚ Start singleton â”‚â”€â”€â”€â”€â–¶â”‚ Write session heading    â”‚
  â”‚   hook       â”‚     â”‚ memsearch watch â”‚     â”‚ to today's memory .md    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ (PID file lock) â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                              â”‚                         â–¼
                              â–¼                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ Inject recent memories + â”‚
                       â”‚ watch monitors  â”‚       â”‚ Memory Tools instructionsâ”‚
                       â”‚ .memsearch/     â”‚       â”‚ { "additionalContext" }  â”‚
                       â”‚   memory/*.md   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       (background, 1500ms debounce, auto-sync on change)

  ğŸ’¬ EVERY USER PROMPT
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ UserPromptSubmit â”‚â”€â”€â”€â”€â–¶â”‚ memsearch search â”‚â”€â”€â”€â”€â–¶â”‚ Inject top-3       â”‚
  â”‚   hook           â”‚     â”‚ "$user_prompt"   â”‚     â”‚ relevant memories  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ --top-k 3        â”‚     â”‚ + chunk_hash IDs   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           (skip if < 10 chars)

  ğŸ›‘ WHEN CLAUDE FINISHES RESPONDING
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Stop    â”‚â”€â”€â”€â”€â–¶â”‚ parse-transcript.sh  â”‚â”€â”€â”€â”€â–¶â”‚ claude -p --model    â”‚
  â”‚(command, â”‚     â”‚ (truncate + format)  â”‚     â”‚ haiku summarizes     â”‚
  â”‚  async)  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
                                                  â–¼
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â”‚ Append summary with  â”‚
                                           â”‚ session/turn anchors â”‚
                                           â”‚ to YYYY-MM-DD.md     â”‚
                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â””â”€â”€â–¶ watch detects change
                                                       â†’ auto-sync

  ğŸ‘‹ SESSION END
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ SessionEnd   â”‚â”€â”€â”€â”€ stop watch process (cleanup)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸª Hook Summary

| Hook | Type | What it does |
|------|------|-------------|
| **SessionStart** | command | Start `memsearch watch` singleton + write session heading + inject recent memories & Memory Tools |
| **UserPromptSubmit** | command | Semantic search on user prompt â†’ inject relevant memories with `chunk_hash` |
| **Stop** | command (async) | Parse transcript â†’ `claude -p --model haiku` summary â†’ write to daily `.md` with session anchors |
| **SessionEnd** | command | Stop the `memsearch watch` process |

## ğŸ” Progressive Disclosure

Memory retrieval uses a three-layer progressive disclosure model. The main Claude agent decides when to drill deeper.

```
  L1: ğŸ“‹ Auto-injected (UserPromptSubmit hook)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Every prompt â†’ top-k search results with chunk_hash + 200-char preview

  L2: ğŸ“– On-demand expand (memsearch expand)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Agent runs: memsearch expand <chunk_hash>
  â†’ Full markdown section + session/turn anchor metadata

  L3: ğŸ’¬ Transcript drill-down (memsearch transcript)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Agent runs: memsearch transcript <jsonl_path> --turn <uuid> --context 3
  â†’ Original conversation turns from the JSONL transcript
```

Each memory summary includes an HTML comment anchor:
```markdown
### 14:30
<!-- session:abc123 turn:def456 transcript:/path/to/session.jsonl -->
- Implemented caching system with Redis L1 and in-process LRU L2
```

The anchor links the chunk back to its source session, enabling L2â†’L3 drill-down.

## ğŸ“ Memory Storage

All memories live in **`.memsearch/memory/`** inside your project directory:

```
your-project/
â””â”€â”€ .memsearch/
    â”œâ”€â”€ .watch.pid        â† singleton watcher PID
    â””â”€â”€ memory/
        â”œâ”€â”€ 2026-02-07.md
        â”œâ”€â”€ 2026-02-08.md
        â””â”€â”€ 2026-02-09.md    â† today's session summaries
```

Each file contains session summaries in plain markdown:

```markdown
## Session 14:30

### 14:30
<!-- session:abc123 turn:def456 transcript:/home/user/.claude/projects/.../abc123.jsonl -->
- Implemented caching system with Redis L1 and in-process LRU L2
- Fixed N+1 query issue in order-service using selectinload
- Decided to use Prometheus counters for cache hit/miss metrics

## Session 17:45

### 17:45
<!-- session:ghi789 turn:jkl012 transcript:/home/user/.claude/projects/.../ghi789.jsonl -->
- Debugged React hydration mismatch â€” Date.now() during SSR
- Added comprehensive test suite for the caching middleware
```

**ğŸ“ Markdown is the source of truth.** The Milvus vector index is a derived cache that can be rebuilt at any time with `memsearch index .memsearch/memory/`.

## âš–ï¸ memsearch vs claude-mem

| | ğŸ§  memsearch | claude-mem |
|---|---|---|
| **Architecture** | ğŸª¶ 4 shell hooks + 1 watch process â€” that's it | Node.js/Bun Worker service + Express server + React UI |
| **Integration** | ğŸ”§ Native hooks + CLI â€” zero IPC overhead | MCP server (stdio) â€” tool definitions permanently consume context window |
| **Memory recall** | âœ… **Automatic** â€” semantic search on every prompt via hook | ğŸ”§ **Agent-driven** â€” Claude must explicitly call MCP `search` tool |
| **Progressive disclosure** | ğŸ” **3-layer, auto-triggered**: hook injects top-k â†’ `expand` â†’ `transcript` drill-down | ğŸ” **3-layer, all manual**: `search` â†’ `timeline` â†’ `get_observations` (all require explicit tool calls) |
| **Session summary** | ğŸ’° `claude -p --model haiku` â€” one cheap call, runs async | ğŸ’¸ Observation on every tool use + session summary â€” more API calls at scale |
| **Vector backend** | ğŸš€ **Milvus** â€” hybrid search (dense + BM25), scales from embedded to distributed cluster | Chroma â€” dense only, limited scaling path |
| **Storage format** | ğŸ“ Transparent `.md` files â€” human-readable, git-friendly | Opaque SQLite + Chroma binary |
| **Index sync** | ğŸ”„ `memsearch watch` singleton â€” auto-debounced background sync | Automatic observation writes via hooks, but no unified background sync |
| **Data portability** | ğŸ“¦ Copy `.memsearch/memory/*.md` â€” done | Export from SQLite + Chroma |
| **Runtime dependency** | Python (`memsearch` CLI) + `claude` CLI | Node.js + Bun + MCP runtime |
| **Context window cost** | ğŸª¶ Minimal â€” hook injects only top-k results as plain text | ğŸ‹ï¸ MCP tool definitions always loaded + each tool call/result consumes context |
| **Cost per session** | ğŸ’µ ~1 Haiku call for summary | ğŸ’¸ Multiple Claude API calls for observation compression |

### ğŸ—ï¸ Key design differences

The fundamental difference is **automatic vs agent-driven** memory recall:

**memsearch** injects relevant memories into **every prompt** via hooks â€” Claude doesn't need to decide whether to search, it just gets the context. Progressive disclosure starts automatically (L1 via hook), and only deeper layers (L2 expand, L3 transcript) require explicit CLI calls. The architecture is **lightweight by design**: shell hooks â†’ CLI â†’ markdown â†’ Milvus. No MCP servers consuming context window, no background services requiring ports, no opaque binary databases. The entire system is auditable by reading a handful of shell scripts and `.md` files.

**claude-mem** gives Claude **MCP tools** to search, explore timelines, and fetch full observations â€” a 3-layer system as well, but all three layers require Claude to **proactively decide** to invoke them. This is more flexible (Claude controls when and what to recall) but means memories are only retrieved when Claude thinks to ask, and MCP tool definitions permanently occupy context window space. The full-stack architecture (Worker service + SQLite + Chroma + React UI) offers richer features like a web viewer, but with significant complexity cost.

## ğŸ“‚ Plugin Files

```
ccplugin/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json              # Plugin manifest
â””â”€â”€ hooks/
    â”œâ”€â”€ hooks.json               # Hook definitions (4 hooks)
    â”œâ”€â”€ common.sh                # Shared setup: env, PATH, memsearch detection, watch management
    â”œâ”€â”€ session-start.sh         # Start watch + write session heading + inject memories & tools
    â”œâ”€â”€ user-prompt-submit.sh    # Semantic search on prompt â†’ inject memories with chunk_hash
    â”œâ”€â”€ stop.sh                  # Parse transcript â†’ haiku summary â†’ append to daily .md
    â”œâ”€â”€ parse-transcript.sh      # Deterministic JSONLâ†’text parser with truncation
    â””â”€â”€ session-end.sh           # Stop watch process
```

## ğŸ› ï¸ The `memsearch` CLI

This plugin is built entirely on the [`memsearch`](../README.md) CLI â€” every hook is just a shell script calling `memsearch` subcommands. Here's what's available:

| Command | Used by | What it does |
|---------|---------|-------------|
| `search <query>` | UserPromptSubmit hook | Semantic search over indexed memories (`-k` for top-K, `-j` for JSON) |
| `watch <paths>` | SessionStart hook | Background watcher that auto-indexes on file changes (debounced) |
| `index <paths>` | Manual / rebuild | One-shot index of markdown files (`--force` to re-index all) |
| `expand <chunk_hash>` | Agent (L2 disclosure) | Show full markdown section around a chunk, with anchor metadata |
| `transcript <jsonl>` | Agent (L3 disclosure) | Parse Claude Code JSONL transcript into readable conversation turns |
| `compact` | Manual | LLM-powered compression of old memories into summaries |
| `config init\|list\|get\|set` | Quick Start | Interactive config wizard, view/modify settings |
| `stats` | Manual | Show index statistics (collection size, chunk count) |
| `reset` | Manual | Drop all indexed data (requires `--yes` to confirm) |

The progressive disclosure commands (`expand` and `transcript`) are the main interaction point for the Claude agent â€” details below.

### `memsearch expand <chunk_hash>`

Look up a chunk by hash in the Milvus index and display the full markdown section around it.

```bash
# Show full section
memsearch expand abc123def456

# JSON output with anchor metadata (session/turn/transcript path)
memsearch expand abc123def456 --json-output

# Show N lines before/after instead of full section
memsearch expand abc123def456 --lines 10
```

### `memsearch transcript <jsonl_path>`

Parse a Claude Code JSONL transcript and display conversation turns.

```bash
# Show index of all turns
memsearch transcript /path/to/session.jsonl

# Show context around a specific turn (prefix match on UUID)
memsearch transcript /path/to/session.jsonl --turn bffc0c1b --context 3

# JSON output
memsearch transcript /path/to/session.jsonl --turn bffc0c1b --json-output
```

